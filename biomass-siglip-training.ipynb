{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":268942,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":230141,"modelId":251887}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SigLIP Feature Extraction and Gradient Boosting Ensemble Training Pipeline\n\nI'll use a hybrid approach by combining \"frozen\" deep learning embeddings from a pre-trained Vision-Language model (SigLIP) with traditional statistical machine learning models (Gradient Boosting) to predict different types of dry biomass (Clover, Green, Dead, Total, etc.).","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport random\nimport pickle\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\n\nimport torch\nfrom PIL import Image\nfrom transformers import AutoModel, AutoImageProcessor, AutoTokenizer\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import r2_score\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:12.733270Z","iopub.execute_input":"2026-02-04T13:10:12.733824Z","iopub.status.idle":"2026-02-04T13:10:46.209363Z","shell.execute_reply.started":"2026-02-04T13:10:12.733786Z","shell.execute_reply":"2026-02-04T13:10:46.208746Z"}},"outputs":[{"name":"stderr","text":"2026-02-04 13:10:27.160075: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770210627.353654      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770210627.409086      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770210627.870268      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770210627.870309      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770210627.870312      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770210627.870314      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"@dataclass\nclass Config:\n    DATA_PATH: Path = Path(\"/kaggle/input/csiro-biomass/\")\n    SIGLIP_PATH: str = \"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\"\n    OUTPUT_DIR: Path = Path(\"./siglip_models\")\n    \n    SEED: int = 42\n    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    PATCH_SIZE: int = 520\n    OVERLAP: int = 16\n    N_FOLDS: int = 5\n    \n    TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n    TRAIN_TARGETS = ['Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']  # Skip Clover (always 0)\n    \n    TARGET_MAX = {\n        \"Dry_Clover_g\": 71.7865,\n        \"Dry_Dead_g\": 83.8407,\n        \"Dry_Green_g\": 157.9836,\n        \"Dry_Total_g\": 185.70,\n        \"GDM_g\": 157.9836,\n    }\n\n\ncfg = Config()\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.210605Z","iopub.execute_input":"2026-02-04T13:10:46.211334Z","iopub.status.idle":"2026-02-04T13:10:46.217520Z","shell.execute_reply.started":"2026-02-04T13:10:46.211308Z","shell.execute_reply":"2026-02-04T13:10:46.216840Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\nset_seed(cfg.SEED)\nprint(f\"Device: {cfg.DEVICE}\")\nprint(f\"Output dir: {cfg.OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.218539Z","iopub.execute_input":"2026-02-04T13:10:46.218816Z","iopub.status.idle":"2026-02-04T13:10:46.238246Z","shell.execute_reply.started":"2026-02-04T13:10:46.218787Z","shell.execute_reply":"2026-02-04T13:10:46.237522Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nOutput dir: siglip_models\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def pivot_table(df: pd.DataFrame) -> pd.DataFrame:\n    \n    df_pt = pd.pivot_table(\n        df, \n        values='target', \n        index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], \n        columns='target_name', \n        aggfunc='mean'\n    ).reset_index()\n\n    return df_pt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.240463Z","iopub.execute_input":"2026-02-04T13:10:46.241050Z","iopub.status.idle":"2026-02-04T13:10:46.245057Z","shell.execute_reply.started":"2026-02-04T13:10:46.241019Z","shell.execute_reply":"2026-02-04T13:10:46.244396Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_robust_stratified_folds(df, n_splits=5, seed=42):\n\n    df = df.copy().reset_index(drop=True)\n\n    # Feature Engineering\n    \n    # qcut: sort all the biomass values and split them into three equally sized groups\n    df['bin_total'] = pd.qcut(df['Dry_Total_g'], q=3, labels=[\"L\", \"M\", \"H\"])\n\n    living_mass = df['Dry_Clover_g'] + df['Dry_Green_g']\n    # calculate what percentage of living plant matter is clover\n    df['clover_frac'] = df['Dry_Clover_g'] / (living_mass + 1e-6)\n\n    # manual boundaries of low: 0-20%, high: 20-100% to ensuere that we don't put all clover rich samples in one fold\n    df['bin_clover'] = pd.cut(df['clover_frac'], bins=[-0.1, 0.2, 1.1], labels=[\"Lo\", \"Hi\"])\n\n    df['state_key'] = df['State'].astype(str) #covert into str so we can combine it later\n\n    # Define Hierarchy Keys\n    df['key_L1'] = df['state_key'] + \"_\" + df['bin_total'].astype(str) + \"_\" + df['bin_clover'].astype(str) # dream scenario - balance everything\n    df['key_L2'] = df['state_key'] + \"_\" + df['bin_total'].astype(str) # just try state and total mass\n    df['key_L3'] = df['state_key']\n\n    # for robustness - check if the groups are big enough >= 5 samples\n    \n    df['final_stratify'] = df['key_L1']\n    counts = df['final_stratify'].value_counts()\n    rare_keys = counts[counts < n_splits].index\n\n    #overwrite those keys with a simpler state and total mass key like WA_Hi\n    mask_rare_L1 = df['final_stratify'].isin(rare_keys) # panda series (boolean)\n    df.loc[mask_rare_L1, 'final_stratify'] = df.loc[mask_rare_L1, 'key_L2']\n\n    #check again and downgrade to L3 if needed\n    counts = df['final_stratify'].value_counts()\n    rare_keys = counts[counts < n_splits].index\n    mask_rare_L2 = df['final_stratify'].isin(rare_keys)\n    df.loc[mask_rare_L2, 'final_stratify'] = df.loc[mask_rare_L2, 'key_L3']\n\n    #final safety net\n    counts = df['final_stratify'].value_counts()\n    rare_keys = counts[counts < n_splits].index\n    if len(rare_keys) > 0:\n        print(f\"Warning: Dropping {len(rare_keys)} extremely rare buckets to 'Misc'\")\n        df.loc[df['final_stratify'].isin(rare_keys), 'final_stratify'] = 'Misc'\n\n    # Perform Split\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    \n    df['fold'] = -1\n    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['final_stratify'])):\n        df.loc[val_idx, 'fold'] = fold\n        \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.246123Z","iopub.execute_input":"2026-02-04T13:10:46.246917Z","iopub.status.idle":"2026-02-04T13:10:46.261299Z","shell.execute_reply.started":"2026-02-04T13:10:46.246892Z","shell.execute_reply":"2026-02-04T13:10:46.260703Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#Feature Extraction\n\ndef split_image(image, patch_size=520, overlap=16):\n    \"\"\"\n    Cut the large image into smaller squares so the model can look at them one by one.\n    Takes the image, the desired square size (520px), and how much the squares should overlap (16px).\n    \"\"\"\n    h, w, c = image.shape\n    stride = patch_size - overlap #step size - move 504px for the next patch instead of 520px to include 16px of previous patch(context)\n    patches = []\n    \n    for y in range(0, h, stride):\n        for x in range(0, w, stride):\n            y2 = min(y + patch_size, h)\n            x2 = min(x + patch_size, w)\n            y1 = max(0, y2 - patch_size)\n            x1 = max(0, x2 - patch_size)\n            patch = image[y1:y2, x1:x2, :]\n            patches.append(patch)\n            \n    return patches\n\ndef compute_embeddings(model_path, df):\n    \"\"\" \n    Loads the SigLIP model and loops through every single image and converts it into a list of numbers (embedding).\n    \"\"\"\n    print(f\"Computing Embeddings for {len(df)} images...\")\n    model = AutoModel.from_pretrained(model_path, local_files_only=True).eval().to(cfg.DEVICE)\n    processor = AutoImageProcessor.from_pretrained(model_path, local_files_only=True)\n    \n    EMBEDDINGS = []\n    \n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        try:\n            img = cv2.imread(row['image_path']) #converts image into a grid of numbers from 0-255\n            \n            if img is None:\n                raise ValueError(\"Image not found\")\n                \n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            patches = split_image(img, patch_size=cfg.PATCH_SIZE, overlap=cfg.OVERLAP)\n            #convert patches from numpy arrays to PIL images because that's what HF processor prefers as input.\n            images = [Image.fromarray(p) for p in patches]\n            \n            inputs = processor(images=images, return_tensors=\"pt\").to(cfg.DEVICE) #converts numbers from opencv into tensors\n            with torch.no_grad():\n                features = model.get_image_features(**inputs) #look at a batch of patches and output a vector for each\n            \n            # take the average of all patches into a single vector to represent an image.\n            avg_embed = features.mean(dim=0).cpu().numpy()\n            EMBEDDINGS.append(avg_embed)\n            \n        except Exception as e:\n            \n            print(f\"Error processing {row['image_path']}: {e}\")\n            EMBEDDINGS.append(np.zeros(1152))\n        \n    torch.cuda.empty_cache()\n    del model\n    gc.collect()\n    return np.stack(EMBEDDINGS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.262176Z","iopub.execute_input":"2026-02-04T13:10:46.262612Z","iopub.status.idle":"2026-02-04T13:10:46.276999Z","shell.execute_reply.started":"2026-02-04T13:10:46.262590Z","shell.execute_reply":"2026-02-04T13:10:46.276356Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def generate_semantic_features(image_embeddings_np, model_path):\n    \n    print(\"Generating Semantic Features...\")\n    model = AutoModel.from_pretrained(model_path, local_files_only=True).to(cfg.DEVICE)\n    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n    \n    concept_groups = {\n        \"bare\": [\"bare soil\", \"dirt ground\", \"sparse vegetation\", \"exposed earth\"],    #average the results of 4 similar phrases to get an accurate signal\n        \"sparse\": [\"low density pasture\", \"thin grass\", \"short clipped grass\"],\n        \"medium\": [\"average pasture cover\", \"medium height grass\", \"grazed pasture\"],\n        \"dense\": [\"dense tall pasture\", \"thick grassy volume\", \"high biomass\", \"overgrown vegetation\"],\n        \"green\": [\"lush green vibrant pasture\", \"photosynthesizing leaves\", \"fresh growth\"],\n        \"dead\": [\"dry brown dead grass\", \"yellow straw\", \"senesced material\", \"standing hay\"],\n        \"clover\": [\"white clover\", \"trifolium repens\", \"broadleaf legume\", \"clover flowers\"],\n        \"grass\": [\"ryegrass\", \"blade-like leaves\", \"fescue\", \"grassy sward\"]\n    }\n    \n    concept_vectors = {}\n    with torch.no_grad():\n        for name, prompts in concept_groups.items():\n            inputs = tokenizer(prompts, padding=\"max_length\", return_tensors=\"pt\").to(cfg.DEVICE)\n            emb = model.get_text_features(**inputs) #results in a matrix of shape (4, 1152) -> 4 phrases and 1152 features.\n            emb = emb / emb.norm(p=2, dim=-1, keepdim=True) # a / |a|\n            concept_vectors[name] = emb.mean(dim=0, keepdim=True) #use the average of the 4 phrase vectors to create 1 master vector\n            \n    img_tensor = torch.tensor(image_embeddings_np, dtype=torch.float32).to(cfg.DEVICE)\n    img_tensor = img_tensor / img_tensor.norm(p=2, dim=-1, keepdim=True) #b / |b|\n\n    #both image and phrase vectors represent a single point in a 1152 dimensional space\n    #length of both vectors is 1 because they are normalized\n    scores = {}\n    for name, vec in concept_vectors.items():\n        #use geometric interpretation of dot product to get the scores that represent the cosine similarity between the 2 vectors.\n        #the scores are on a range of 0-1. cosine similarity or cos(theta) = a * b / |a| * |b|\n        scores[name] = torch.matmul(img_tensor, vec.T).cpu().numpy().flatten() #results in a list of scores for each image which becomes value in a dict\n        \n    df_scores = pd.DataFrame(scores)\n    df_scores['ratio_greenness'] = df_scores['green'] / (df_scores['green'] + df_scores['dead'] + 1e-6) #what percentage of grass is alive\n    df_scores['ratio_clover'] = df_scores['clover'] / (df_scores['clover'] + df_scores['grass'] + 1e-6)\n    #meassure density (ground clover). this is the strongest predictor of biomass\n    df_scores['ratio_cover'] = (df_scores['dense'] + df_scores['medium']) / (df_scores['bare'] + df_scores['sparse'] + 1e-6)\n    \n    torch.cuda.empty_cache()\n    del model\n    gc.collect()\n    return df_scores.values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.277871Z","iopub.execute_input":"2026-02-04T13:10:46.278240Z","iopub.status.idle":"2026-02-04T13:10:46.292469Z","shell.execute_reply.started":"2026-02-04T13:10:46.278219Z","shell.execute_reply":"2026-02-04T13:10:46.291764Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class SupervisedEmbeddingEngine:\n    \"\"\"\n    Custom Feature Engineering class that compresses the noisy input (1,152 columns) into a small, highly potent set of features (approx. 30-40 columns).\n    It combines three different mathematical techniques (PCA, PLS, GMM) into one pipeline.\n    \"\"\"\n    def __init__(self, n_pca=0.80, n_pls=8, n_gmm=6, random_state=42):\n        self.scaler = StandardScaler()\n        #Unsupervised Compression. It will condense the data until it retains 80% of the original information\n        self.pca = PCA(n_components=n_pca, random_state=random_state)\n        #Supervised Extraction. This is the smart tool. It looks for 8 specific patterns that correlate with Target (Biomass).\n        self.pls = PLSRegression(n_components=n_pls, scale=False)\n        #Clustering. It will try to sort every image into one of 6 types\n        self.gmm = GaussianMixture(n_components=n_gmm, covariance_type='diag', random_state=random_state)\n        self.pls_fitted_ = False\n\n    # the training - fit function is the learner. It calculates math rules based on the data you give it. It just saves these numbers in its internal memory.\n    def fit(self, X, y=None, X_semantic=None):\n        # Scale\n        X_scaled = self.scaler.fit_transform(X) #It calculates the mean and s.d of every column in training set and stores it. Then, it standardizes X\n        \n        # Unsupervised - train pca and gmm\n        self.pca.fit(X_scaled)\n        self.gmm.fit(X_scaled)\n        \n        # Supervised\n        if y is not None:\n            self.pls.fit(X_scaled, y) #learn relationships between image features and bimoass targets\n            self.pls_fitted_ = True\n        return self\n\n    #the execution - it applies the saved rules in fit function to modify the data\n    def transform(self, X, X_semantic=None):\n        X_scaled = self.scaler.transform(X) #standardizes the data based on the old mean and s.d. we learned in fit\n\n        #It performs a matrix multiplication between scaled data and the PCA Eigenvectors (the projection matrix) stored inside self.pca.\n        #The Result: A matrix of roughly 25-30 columns capturing the \"General Structure\" of the images.\n        features = [self.pca.transform(X_scaled)]\n        \n        if self.pls_fitted_:\n            features.append(self.pls.transform(X_scaled))  #matrix multiplication with pls weights\n            \n        features.append(self.gmm.predict_proba(X_scaled))\n        \n        if X_semantic is not None:\n            # Normalize using INPUT's own mean/std\n            sem_norm = (X_semantic - np.mean(X_semantic, axis=0)) / (np.std(X_semantic, axis=0) + 1e-6)\n            features.append(sem_norm)\n            \n        return np.hstack(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.293438Z","iopub.execute_input":"2026-02-04T13:10:46.293735Z","iopub.status.idle":"2026-02-04T13:10:46.310526Z","shell.execute_reply.started":"2026-02-04T13:10:46.293715Z","shell.execute_reply":"2026-02-04T13:10:46.309802Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# MODEL CONFIGURATIONS\nMODEL_CONFIGS = {\n    'hist': {\n        'class': HistGradientBoostingRegressor,\n        'params': {\n            'max_iter': 300, 'learning_rate': 0.05, 'max_depth': None,\n            'l2_regularization': 0.44, 'random_state': 42\n        }\n    },\n    'gb': {\n        'class': GradientBoostingRegressor,\n        'params': {\n            'n_estimators': 1354, 'learning_rate': 0.010, 'max_depth': 3,\n            'subsample': 0.60, 'random_state': 42\n        }\n    },\n    'cat': {\n        'class': CatBoostRegressor,\n        'params': {\n            'iterations': 1900, 'learning_rate': 0.045, 'depth': 4, 'l2_leaf_reg': 0.56,\n            'random_strength': 0.045, 'bagging_temperature': 0.98, 'verbose': 0,\n            'random_state': 42, 'allow_writing_files': False\n        }\n    },\n    'lgbm': {\n        'class': LGBMRegressor,\n        'params': {\n            'n_estimators': 807, 'learning_rate': 0.014, 'num_leaves': 48,\n            'min_child_samples': 19, 'subsample': 0.745, 'colsample_bytree': 0.745,\n            'reg_alpha': 0.21, 'reg_lambda': 3.78, 'verbose': -1, 'random_state': 42\n        }\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.312120Z","iopub.execute_input":"2026-02-04T13:10:46.312386Z","iopub.status.idle":"2026-02-04T13:10:46.322803Z","shell.execute_reply.started":"2026-02-04T13:10:46.312365Z","shell.execute_reply":"2026-02-04T13:10:46.322190Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_and_save_models():\n    print(\"\\n\" + \"=\"*80)\n    print(\"LOADING DATA\")\n    print(\"=\"*80)\n    \n    # Load train.csv and pivot (matches original)\n    train_long = pd.read_csv(cfg.DATA_PATH / \"train.csv\")\n    train_df = pivot_table(train_long)\n    \n    # Fill any missing targets\n    for t in cfg.TARGET_NAMES:\n        if t not in train_df.columns:\n            train_df[t] = 0.0\n    train_df[cfg.TARGET_NAMES] = train_df[cfg.TARGET_NAMES].fillna(0.0)\n    \n    # Create folds\n    train_df = get_robust_stratified_folds(train_df, n_splits=cfg.N_FOLDS, seed=cfg.SEED)\n    \n    # Fix paths (matches original)\n    if not str(train_df['image_path'].iloc[0]).startswith('/'):\n        train_df['image_path'] = train_df['image_path'].apply(\n            lambda p: str(cfg.DATA_PATH / 'train' / os.path.basename(p))\n        )\n    \n    print(f\"Train samples: {len(train_df)}\")\n    print(f\"Fold distribution:\\n{train_df['fold'].value_counts().sort_index()}\")\n    \n    # Compute embeddings\n    print(\"\\n\" + \"=\"*80)\n    print(\"COMPUTING EMBEDDINGS\")\n    print(\"=\"*80)\n    \n    train_embeddings = compute_embeddings(cfg.SIGLIP_PATH, train_df)\n    \n    # Create Feature DataFrame\n    emb_cols = [f\"emb{i}\" for i in range(train_embeddings.shape[1])]\n    train_feat_df = pd.concat([train_df, pd.DataFrame(train_embeddings, columns=emb_cols)], axis=1)\n    \n    print(f\"Train Features Shape: {train_feat_df.shape}\")\n    \n    # Generate semantic features\n    sem_train = generate_semantic_features(train_embeddings, cfg.SIGLIP_PATH)\n    print(f\"Semantic Features Shape: {sem_train.shape}\")\n    \n    # Prepare data\n    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=np.float32)\n    \n    X_train_full = train_feat_df[emb_cols].values.astype(np.float32) #shape - (N images, 1152)\n    y_train_full = train_feat_df[cfg.TARGET_NAMES].values.astype(np.float32) #shape - (N images, 5)\n    \n    # Storage\n    all_engines = {}\n    all_models = {}\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"TRAINING MODELS\")\n    print(\"=\"*80)\n\n    # cross validation process. Train multiple models on different subsets of the data.\n    for fold in range(cfg.N_FOLDS):\n        print(f\"\\n--- Fold {fold} ---\")\n        \n        #use images not in the fold for training\n        train_mask = train_feat_df['fold'] != fold\n        \n        X_tr = X_train_full[train_mask]\n        #normalize the targets to 0-1 by dividing using max observed value for that target\n        y_tr = y_train_full[train_mask] / target_max_arr\n        sem_tr_fold = sem_train[train_mask]\n        \n        # Fit feature engine (matches original)\n        engine = SupervisedEmbeddingEngine(n_pca=0.80, n_pls=8, n_gmm=6, random_state=cfg.SEED)\n        engine.fit(X_tr, y=y_tr, X_semantic=sem_tr_fold)\n        all_engines[fold] = engine\n        \n        # Transform training data\n        x_tr_eng = engine.transform(X_tr, X_semantic=sem_tr_fold)\n        \n        # Train each model type\n        all_models[fold] = {}\n        \n        for model_name, model_cfg in MODEL_CONFIGS.items():\n            print(f\"  Training {model_name}...\")\n            all_models[fold][model_name] = {}\n\n            #standard regression models usually only predict one number at a time. so we predict each biomass type seperately.\n            for target_name in cfg.TRAIN_TARGETS:\n                k = cfg.TARGET_NAMES.index(target_name)\n                \n                #creates a fresh untrained model ready to learn\n                model = model_cfg['class'](**model_cfg['params'])\n                model.fit(x_tr_eng, y_tr[:, k])\n                #save the brain\n                all_models[fold][model_name][target_name] = model\n        \n        print(f\"  Fold {fold} complete.\")\n    \n    # Save everything\n    print(\"\\n\" + \"=\"*80)\n    print(\"SAVING MODELS\")\n    print(\"=\"*80)\n    \n    with open(cfg.OUTPUT_DIR / \"feature_engines.pkl\", \"wb\") as f:\n        pickle.dump(all_engines, f)\n    print(f\"Saved feature_engines.pkl ({cfg.N_FOLDS} engines)\")\n    \n    with open(cfg.OUTPUT_DIR / \"models.pkl\", \"wb\") as f:\n        pickle.dump(all_models, f)\n    print(f\"Saved models.pkl ({cfg.N_FOLDS} folds × {len(MODEL_CONFIGS)} models × {len(cfg.TRAIN_TARGETS)} targets)\")\n    \n    # Save config\n    config_dict = {\n        'TARGET_NAMES': cfg.TARGET_NAMES,\n        'TRAIN_TARGETS': cfg.TRAIN_TARGETS,\n        'TARGET_MAX': cfg.TARGET_MAX,\n        'N_FOLDS': cfg.N_FOLDS,\n        'SEED': cfg.SEED,\n        'PATCH_SIZE': cfg.PATCH_SIZE,\n        'OVERLAP': cfg.OVERLAP,\n        'emb_cols': emb_cols,\n        'model_names': list(MODEL_CONFIGS.keys()),\n    }\n    with open(cfg.OUTPUT_DIR / \"config.pkl\", \"wb\") as f:\n        pickle.dump(config_dict, f)\n    print(\"Saved config.pkl\")\n    \nif __name__ == \"__main__\":\n    train_and_save_models()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T13:10:46.324853Z","iopub.execute_input":"2026-02-04T13:10:46.325134Z","iopub.status.idle":"2026-02-04T13:21:20.229401Z","shell.execute_reply.started":"2026-02-04T13:10:46.325113Z","shell.execute_reply":"2026-02-04T13:21:20.228655Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nLOADING DATA\n================================================================================\nTrain samples: 357\nFold distribution:\nfold\n0    72\n1    72\n2    71\n3    71\n4    71\nName: count, dtype: int64\n\n================================================================================\nCOMPUTING EMBEDDINGS\n================================================================================\nComputing Embeddings for 357 images...\n","output_type":"stream"},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n100%|██████████| 357/357 [06:32<00:00,  1.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Features Shape: (357, 1172)\nGenerating Semantic Features...\nSemantic Features Shape: (357, 11)\n\n================================================================================\nTRAINING MODELS\n================================================================================\n\n--- Fold 0 ---\n  Training hist...\n  Training gb...\n  Training cat...\n  Training lgbm...\n  Fold 0 complete.\n\n--- Fold 1 ---\n  Training hist...\n  Training gb...\n  Training cat...\n  Training lgbm...\n  Fold 1 complete.\n\n--- Fold 2 ---\n  Training hist...\n  Training gb...\n  Training cat...\n  Training lgbm...\n  Fold 2 complete.\n\n--- Fold 3 ---\n  Training hist...\n  Training gb...\n  Training cat...\n  Training lgbm...\n  Fold 3 complete.\n\n--- Fold 4 ---\n  Training hist...\n  Training gb...\n  Training cat...\n  Training lgbm...\n  Fold 4 complete.\n\n================================================================================\nSAVING MODELS\n================================================================================\nSaved feature_engines.pkl (5 engines)\nSaved models.pkl (5 folds × 4 models × 4 targets)\nSaved config.pkl\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}