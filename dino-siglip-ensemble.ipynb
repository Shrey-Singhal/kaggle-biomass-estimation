{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2728071",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-26T16:31:29.435708Z",
     "iopub.status.busy": "2026-01-26T16:31:29.435380Z",
     "iopub.status.idle": "2026-01-26T16:34:17.590342Z",
     "shell.execute_reply": "2026-01-26T16:34:17.589314Z"
    },
    "papermill": {
     "duration": 168.161371,
     "end_time": "2026-01-26T16:34:17.592187",
     "exception": false,
     "start_time": "2026-01-26T16:31:29.430816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2026-01-26 16:31:49.728552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769445109.908225      23 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769445109.968745      23 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769445110.403927      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769445110.403969      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769445110.403971      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769445110.403974      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "================================================================================\n",
      "PART 1: SIGLIP INFERENCE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PART 2: DINOV3 INFERENCE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOADING TEST DATA\n",
      "================================================================================\n",
      "Test rows (raw): 5\n",
      "Test images: 1\n",
      "Loading pre-trained SigLIP models...\n",
      "  Loaded 5 feature engines\n",
      "  Loaded models for 5 folds\n",
      "Computing SigLIP embeddings for 1 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating semantic features...\n",
      "Running SigLIP inference...\n",
      "  Fold 0...\n",
      "  Fold 1...\n",
      "  Fold 2...\n",
      "  Fold 3...\n",
      "  Fold 4...\n",
      "SigLIP predictions: 1 images\n",
      "Looking for DINO checkpoints...\n",
      "  Found: /kaggle/input/dinov3-5fold/best_model_fold0.pth\n",
      "  Found: /kaggle/input/dinov3-5fold/best_model_fold1.pth\n",
      "  Found: /kaggle/input/dinov3-5fold/best_model_fold2.pth\n",
      "  Found: /kaggle/input/dinov3-5fold/best_model_fold3.pth\n",
      "  Found: /kaggle/input/dinov3-5fold/best_model_fold4.pth\n",
      "Running DINO inference with 5 checkpoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINO predictions: 1 images\n",
      "\n",
      "================================================================================\n",
      "PART 3: ENSEMBLE + SUBMISSION\n",
      "================================================================================\n",
      "Merging predictions on image_id...\n",
      "Merged 1 images\n",
      "  Dry_Green_g: 65% DINO + 35% SigLIP\n",
      "  Dry_Clover_g: DINO only\n",
      "  Dry_Dead_g: 65% DINO + 35% SigLIP\n",
      "\n",
      "Building submission from test.csv template...\n",
      "\n",
      "--- Sanity Checks ---\n",
      "Test rows (expected): 5\n",
      "Submission rows: 5\n",
      "Missing values: 0\n",
      "Columns: ['sample_id', 'target']\n",
      "\n",
      "✓ Saved submission.csv with 5 rows\n",
      "\n",
      "First 10 rows:\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   2.464985\n",
      "1    ID1001187975__Dry_Dead_g  30.822813\n",
      "2   ID1001187975__Dry_Green_g  31.321903\n",
      "3   ID1001187975__Dry_Total_g  64.609703\n",
      "4         ID1001187975__GDM_g  33.786888\n",
      "\n",
      "Stats:\n",
      "count     5.000000\n",
      "mean     32.601258\n",
      "std      22.016703\n",
      "min       2.464985\n",
      "25%      30.822813\n",
      "50%      31.321903\n",
      "75%      33.786888\n",
      "max      64.609703\n",
      "Name: target, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "DONE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CSIRO BIOMASS - SUBMISSION NOTEBOOK (INFERENCE ONLY)\n",
    "This notebook ONLY does inference - no training.\n",
    "All models are loaded from pre-trained checkpoints.\n",
    "\n",
    "Required Kaggle datasets:\n",
    "1. csiro-biomass (competition data)\n",
    "2. google-siglip-so400m-patch14-384 (SigLIP model)\n",
    "3. My siglip_models dataset (from training notebook)\n",
    "4. My dinov3_models dataset (from Colab training)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoTokenizer\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# CONFIGURATION\n",
    "@dataclass\n",
    "class Config:\n",
    "    DATA_PATH: Path = Path(\"/kaggle/input/csiro-biomass/\")\n",
    "    SIGLIP_PATH: str = \"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\"\n",
    "    SIGLIP_MODELS_DIR: Path = Path(\"/kaggle/input/siglip-trainer\")\n",
    "    DINO_MODELS_DIR: Path = Path(\"/kaggle/input/dinov3-5fold\")\n",
    "    \n",
    "    SEED: int = 42\n",
    "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # SigLIP settings\n",
    "    PATCH_SIZE: int = 520\n",
    "    OVERLAP: int = 16\n",
    "    \n",
    "    # DINOv3 settings\n",
    "    DINO_MODEL_NAME: str = \"vit_large_patch16_dinov3\"\n",
    "    DINO_IMG_SIZE: int = 512\n",
    "    DINO_DROPOUT: float = 0.15\n",
    "    DINO_BATCH_SIZE: int = 8\n",
    "    \n",
    "    # Targets\n",
    "    TARGET_NAMES = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
    "    ALL_TARGET_COLS = [\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "    PRIMARY_TARGETS = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\"]\n",
    "    \n",
    "    TARGET_MAX = {\n",
    "        \"Dry_Clover_g\": 71.7865,\n",
    "        \"Dry_Dead_g\": 83.8407,\n",
    "        \"Dry_Green_g\": 157.9836,\n",
    "        \"Dry_Total_g\": 185.70,\n",
    "        \"GDM_g\": 157.9836,\n",
    "    }\n",
    "    \n",
    "    # Ensemble weights\n",
    "    W_SIGLIP: float = 0.35\n",
    "    W_DINO: float = 0.65\n",
    "    DINO_ONLY_CLOVER: bool = True \n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(cfg.SEED)\n",
    "print(f\"Device: {cfg.DEVICE}\")\n",
    "\n",
    "def pivot_table_test(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert long format test.csv to wide format.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['target'] = 0\n",
    "    df_pt = pd.pivot_table(\n",
    "        df,\n",
    "        values='target',\n",
    "        index='image_path',\n",
    "        columns='target_name',\n",
    "        aggfunc='mean'              #If the data had two rows for the same image and the same target: aggfunc: mean - averages it\n",
    "    ).reset_index()\n",
    "    return df_pt\n",
    "\n",
    "\n",
    "# PART 1: SIGLIP INFERENCE\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 1: SIGLIP INFERENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def split_image(image: np.ndarray, patch_size: int = 520, overlap: int = 16):\n",
    "    h, w, c = image.shape\n",
    "    stride = patch_size - overlap\n",
    "    patches = []\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            y2 = min(y + patch_size, h)\n",
    "            x2 = min(x + patch_size, w)\n",
    "            y1 = max(0, y2 - patch_size)\n",
    "            x1 = max(0, x2 - patch_size)\n",
    "            patches.append(image[y1:y2, x1:x2, :])\n",
    "    return patches\n",
    "\n",
    "def compute_siglip_embeddings(model_path: str, df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Compute SigLIP embeddings for images.\"\"\"\n",
    "    print(f\"Computing SigLIP embeddings for {len(df)} images...\")\n",
    "    \n",
    "    model = AutoModel.from_pretrained(model_path, local_files_only=True).eval().to(cfg.DEVICE)\n",
    "    processor = AutoImageProcessor.from_pretrained(model_path, local_files_only=True)\n",
    "    \n",
    "    EMBEDDINGS = []\n",
    "    PATCH_BATCH = 12\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img = cv2.imread(row['image_path'])\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Image not found: {row['image_path']}\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            patches = split_image(img, patch_size=cfg.PATCH_SIZE, overlap=cfg.OVERLAP)\n",
    "            images = [Image.fromarray(p) for p in patches]\n",
    "            \n",
    "            feats_list = []\n",
    "            with torch.no_grad():\n",
    "                for i in range(0, len(images), PATCH_BATCH):\n",
    "                    batch_imgs = images[i:i+PATCH_BATCH]\n",
    "                    inputs = processor(images=batch_imgs, return_tensors=\"pt\").to(cfg.DEVICE)\n",
    "                    features = model.get_image_features(**inputs)\n",
    "                    feats_list.append(features)\n",
    "            \n",
    "            features = torch.cat(feats_list, dim=0)\n",
    "            avg_embed = features.mean(dim=0).detach().cpu().numpy()\n",
    "            EMBEDDINGS.append(avg_embed)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing: {e}\")\n",
    "            EMBEDDINGS.append(np.zeros(1152, dtype=np.float32))\n",
    "    \n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return np.stack(EMBEDDINGS)\n",
    "\n",
    "def generate_semantic_features(image_embeddings_np: np.ndarray, model_path: str) -> np.ndarray:\n",
    "    \"\"\"Generate semantic features using text probing.\"\"\"\n",
    "    print(\"Generating semantic features...\")\n",
    "    \n",
    "    model = AutoModel.from_pretrained(model_path, local_files_only=True).to(cfg.DEVICE)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "    \n",
    "    concept_groups = {\n",
    "        \"bare\": [\"bare soil\", \"dirt ground\", \"sparse vegetation\", \"exposed earth\"],\n",
    "        \"sparse\": [\"low density pasture\", \"thin grass\", \"short clipped grass\"],\n",
    "        \"medium\": [\"average pasture cover\", \"medium height grass\", \"grazed pasture\"],\n",
    "        \"dense\": [\"dense tall pasture\", \"thick grassy volume\", \"high biomass\", \"overgrown vegetation\"],\n",
    "        \"green\": [\"lush green vibrant pasture\", \"photosynthesizing leaves\", \"fresh growth\"],\n",
    "        \"dead\": [\"dry brown dead grass\", \"yellow straw\", \"senesced material\", \"standing hay\"],\n",
    "        \"clover\": [\"white clover\", \"trifolium repens\", \"broadleaf legume\", \"clover flowers\"],\n",
    "        \"grass\": [\"ryegrass\", \"blade-like leaves\", \"fescue\", \"grassy sward\"],\n",
    "    }\n",
    "    \n",
    "    concept_vectors = {}\n",
    "    with torch.no_grad():\n",
    "        for name, prompts in concept_groups.items():\n",
    "            inputs = tokenizer(prompts, padding=\"max_length\", return_tensors=\"pt\").to(cfg.DEVICE)\n",
    "            emb = model.get_text_features(**inputs)\n",
    "            emb = emb / emb.norm(p=2, dim=-1, keepdim=True)\n",
    "            concept_vectors[name] = emb.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    img_tensor = torch.tensor(image_embeddings_np, dtype=torch.float32).to(cfg.DEVICE)\n",
    "    img_tensor = img_tensor / img_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    scores = {}\n",
    "    for name, vec in concept_vectors.items():\n",
    "        scores[name] = torch.matmul(img_tensor, vec.T).detach().cpu().numpy().flatten()\n",
    "    \n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    df_scores['ratio_greenness'] = df_scores['green'] / (df_scores['green'] + df_scores['dead'] + 1e-6)\n",
    "    df_scores['ratio_clover'] = df_scores['clover'] / (df_scores['clover'] + df_scores['grass'] + 1e-6)\n",
    "    df_scores['ratio_cover'] = (df_scores['dense'] + df_scores['medium']) / (df_scores['bare'] + df_scores['sparse'] + 1e-6)\n",
    "    \n",
    "    del model, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return df_scores.values.astype(np.float32)\n",
    "\n",
    "def run_siglip_inference(test_df_wide):\n",
    "    \"\"\"Run SigLIP inference using pre-trained models.\"\"\"\n",
    "    \n",
    "    print(\"Loading pre-trained SigLIP models...\")\n",
    "    \n",
    "    with open(cfg.SIGLIP_MODELS_DIR / \"feature_engines.pkl\", \"rb\") as f:\n",
    "        all_engines = pickle.load(f)\n",
    "    print(f\"  Loaded {len(all_engines)} feature engines\")\n",
    "    \n",
    "    with open(cfg.SIGLIP_MODELS_DIR / \"models.pkl\", \"rb\") as f:\n",
    "        all_models = pickle.load(f)\n",
    "    print(f\"  Loaded models for {len(all_models)} folds\")\n",
    "    \n",
    "    with open(cfg.SIGLIP_MODELS_DIR / \"config.pkl\", \"rb\") as f:\n",
    "        saved_config = pickle.load(f)\n",
    "    \n",
    "    test_embeddings = compute_siglip_embeddings(cfg.SIGLIP_PATH, test_df_wide)\n",
    "    \n",
    "    sem_test = generate_semantic_features(test_embeddings, cfg.SIGLIP_PATH)\n",
    "    \n",
    "    print(\"Running SigLIP inference...\")\n",
    "    \n",
    "    target_max_arr = np.array([cfg.TARGET_MAX[t] for t in cfg.TARGET_NAMES], dtype=np.float32)\n",
    "    n_folds = saved_config['N_FOLDS']\n",
    "    model_names = saved_config['model_names']\n",
    "    train_targets = saved_config['TRAIN_TARGETS']\n",
    "    \n",
    "    y_pred_test_accum = np.zeros((len(test_df_wide), len(cfg.TARGET_NAMES)), dtype=np.float32)\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        print(f\"  Fold {fold}...\")\n",
    "        \n",
    "        engine = all_engines[fold]\n",
    "        # Semantic features are normalized using their OWN mean/std inside transform()\n",
    "        # This matches the training code behavior\n",
    "        x_te_eng = engine.transform(test_embeddings, X_semantic=sem_test)\n",
    "        \n",
    "        fold_pred = np.zeros((len(test_df_wide), len(cfg.TARGET_NAMES)), dtype=np.float32)\n",
    "        \n",
    "        for model_name in model_names:\n",
    "            model_pred = np.zeros((len(test_df_wide), len(cfg.TARGET_NAMES)), dtype=np.float32)\n",
    "            \n",
    "            for target_name in cfg.TARGET_NAMES:\n",
    "                k = cfg.TARGET_NAMES.index(target_name)\n",
    "                \n",
    "                if target_name == 'Dry_Clover_g':\n",
    "                    model_pred[:, k] = 0.0\n",
    "                else:\n",
    "                    model = all_models[fold][model_name][target_name]\n",
    "                    pred = model.predict(x_te_eng).astype(np.float32)\n",
    "                    model_pred[:, k] = pred * target_max_arr[k]\n",
    "            \n",
    "            fold_pred += model_pred\n",
    "        \n",
    "        fold_pred /= len(model_names)  # Average across model types\n",
    "        y_pred_test_accum += fold_pred\n",
    "    \n",
    "    y_pred_test_accum /= n_folds  # Average across folds\n",
    "    \n",
    "    # Create result DataFrame with image_id\n",
    "    result_df = pd.DataFrame()\n",
    "    result_df['image_id'] = test_df_wide['image_path'].apply(lambda p: Path(p).stem)\n",
    "    \n",
    "    for i, col in enumerate(cfg.TARGET_NAMES):\n",
    "        result_df[col] = y_pred_test_accum[:, i]\n",
    "    \n",
    "    # Post-process\n",
    "    result_df['Dry_Clover_g'] = 0.0\n",
    "    result_df['GDM_g'] = result_df['Dry_Green_g'] + result_df['Dry_Clover_g']\n",
    "    result_df['Dry_Total_g'] = result_df['GDM_g'] + result_df['Dry_Dead_g']\n",
    "    \n",
    "    for col in cfg.TARGET_NAMES:\n",
    "        result_df[col] = result_df[col].clip(lower=0.0)\n",
    "    \n",
    "    print(f\"SigLIP predictions: {len(result_df)} images\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del all_engines, all_models, test_embeddings, sem_test\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# PART 2: DINOV3 INFERENCE\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 2: DINOV3 INFERENCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def clean_image(img):\n",
    "    \"\"\"Remove bottom 10% and inpaint orange date stamps.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    img = img[0:int(h * 0.90), :]\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    mask = cv2.inRange(hsv, np.array([5, 150, 150]), np.array([25, 255, 255]))\n",
    "    mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=2)\n",
    "    if np.sum(mask) > 0:\n",
    "        img = cv2.inpaint(img, mask, 3, cv2.INPAINT_TELEA)\n",
    "    \n",
    "    return img\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(feat_dim // 2, feat_dim * 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        gamma_beta = self.mlp(context)\n",
    "        gamma, beta = torch.chunk(gamma_beta, 2, dim=1)\n",
    "        return gamma, beta\n",
    "\n",
    "class CSIROModelRegressor(nn.Module):\n",
    "    def __init__(self, model_name, dropout=0.2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,  # Always False for inference\n",
    "            num_classes=0,\n",
    "            global_pool=\"avg\",\n",
    "        )\n",
    "        nf = self.backbone.num_features\n",
    "        \n",
    "        self.film = FiLM(nf)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(nf * 3, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "        self.softplus = nn.Softplus(beta=1.0)\n",
    "        \n",
    "        self.register_buffer('max_green', torch.tensor(cfg.TARGET_MAX[\"Dry_Green_g\"]))\n",
    "        self.register_buffer('max_clover', torch.tensor(cfg.TARGET_MAX[\"Dry_Clover_g\"]))\n",
    "        self.register_buffer('max_dead', torch.tensor(cfg.TARGET_MAX[\"Dry_Dead_g\"]))\n",
    "\n",
    "    def forward(self, full_img, left_img, right_img):\n",
    "        full_feat = self.backbone(full_img)\n",
    "        left_feat = self.backbone(left_img)\n",
    "        right_feat = self.backbone(right_img)\n",
    "        \n",
    "        gamma, beta = self.film(full_feat)\n",
    "        left_mod = left_feat * (1.0 + gamma) + beta\n",
    "        right_mod = right_feat * (1.0 + gamma) + beta\n",
    "        \n",
    "        comb = torch.cat([full_feat, left_mod, right_mod], dim=1)\n",
    "        \n",
    "        prim_norm = self.softplus(self.head(comb))\n",
    "        green_norm = prim_norm[:, 0:1]\n",
    "        clover_norm = prim_norm[:, 1:2]\n",
    "        dead_norm = prim_norm[:, 2:3]\n",
    "        \n",
    "        green = green_norm * self.max_green\n",
    "        clover = clover_norm * self.max_clover\n",
    "        dead = dead_norm * self.max_dead\n",
    "        \n",
    "        gdm = green + clover\n",
    "        total = gdm + dead\n",
    "        \n",
    "        # Pack: [Green, Dead, Clover, GDM, Total]\n",
    "        packed = torch.cat([green, dead, clover, gdm, total], dim=1)\n",
    "        return packed\n",
    "\n",
    "class BiomassTestDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_root = str(data_root)\n",
    "        self.transform = transform\n",
    "        self.paths = self.df[\"image_path\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _read_image(self, rel_path):\n",
    "        abs_path = rel_path if os.path.isabs(rel_path) else os.path.join(self.data_root, rel_path)\n",
    "        img = cv2.imread(abs_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read image: {abs_path}\")\n",
    "            img = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rel_path = self.paths[idx]\n",
    "        img = self._read_image(rel_path)\n",
    "        img = clean_image(img)\n",
    "        \n",
    "        h, w, _ = img.shape\n",
    "        mid = w // 2\n",
    "        left = img[:, :mid]\n",
    "        right = img[:, mid:]\n",
    "        full = img\n",
    "        \n",
    "        full = self.transform(image=full)[\"image\"]\n",
    "        left = self.transform(image=left)[\"image\"]\n",
    "        right = self.transform(image=right)[\"image\"]\n",
    "        return full, left, right\n",
    "\n",
    "def get_val_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(height=cfg.DINO_IMG_SIZE, width=cfg.DINO_IMG_SIZE),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_one_dino_model(ckpt_path, loader):\n",
    "    \"\"\"Run inference with one DINO checkpoint.\"\"\"\n",
    "    model = CSIROModelRegressor(\n",
    "        cfg.DINO_MODEL_NAME, \n",
    "        dropout=cfg.DINO_DROPOUT, \n",
    "        pretrained=False  # Always False - we load our own weights\n",
    "    ).to(cfg.DEVICE)\n",
    "    \n",
    "    state = torch.load(ckpt_path, map_location=cfg.DEVICE)\n",
    "    model.load_state_dict(state, strict=True)\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    # FIX: Handle CPU gracefully\n",
    "    use_amp = (cfg.DEVICE == \"cuda\")\n",
    "    \n",
    "    for full, left, right in tqdm(loader, desc=f\"Infer {os.path.basename(ckpt_path)}\", leave=False):\n",
    "        full = full.to(cfg.DEVICE, non_blocking=True)\n",
    "        left = left.to(cfg.DEVICE, non_blocking=True)\n",
    "        right = right.to(cfg.DEVICE, non_blocking=True)\n",
    "        \n",
    "        if use_amp:\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=True):\n",
    "                out = model(full, left, right)\n",
    "        else:\n",
    "            out = model(full, left, right)\n",
    "        \n",
    "        preds.append(out.float().cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def run_dino_inference(test_df_wide):\n",
    "    \"\"\"Run DINOv3 inference using pre-trained models.\"\"\"\n",
    "    \n",
    "    test_ds = BiomassTestDataset(test_df_wide, cfg.DATA_PATH, get_val_transforms())\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.DINO_BATCH_SIZE * 2,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    # Find checkpoints\n",
    "    print(\"Looking for DINO checkpoints...\")\n",
    "    ckpts = []\n",
    "    for fold in range(5):\n",
    "        ckpt = cfg.DINO_MODELS_DIR / f\"best_model_fold{fold}.pth\"\n",
    "        if ckpt.exists():\n",
    "            ckpts.append(str(ckpt))\n",
    "            print(f\"  Found: {ckpt}\")\n",
    "    \n",
    "    if len(ckpts) == 0:\n",
    "        raise FileNotFoundError(f\"No DINO checkpoints found in {cfg.DINO_MODELS_DIR}\")\n",
    "    \n",
    "    # Predict each fold and average\n",
    "    print(f\"Running DINO inference with {len(ckpts)} checkpoints...\")\n",
    "    fold_preds = []\n",
    "    for ckpt in ckpts:\n",
    "        fold_preds.append(predict_one_dino_model(ckpt, test_loader))\n",
    "    \n",
    "    pred_mean = np.mean(np.stack(fold_preds, axis=0), axis=0)\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    result_df['image_id'] = test_df_wide['image_path'].apply(lambda p: Path(p).stem)\n",
    "    result_df['Dry_Green_g'] = pred_mean[:, 0]\n",
    "    result_df['Dry_Dead_g'] = pred_mean[:, 1]\n",
    "    result_df['Dry_Clover_g'] = pred_mean[:, 2]\n",
    "    result_df['GDM_g'] = pred_mean[:, 3]\n",
    "    result_df['Dry_Total_g'] = pred_mean[:, 4]\n",
    "    \n",
    "    print(f\"DINO predictions: {len(result_df)} images\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# PART 3: ENSEMBLE + SUBMISSION\n",
    "def ensemble_and_submit(siglip_preds, dino_preds, test_df_raw):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PART 3: ENSEMBLE + SUBMISSION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"Merging predictions on image_id...\")\n",
    "    \n",
    "    merged = siglip_preds[['image_id']].merge(\n",
    "        dino_preds[['image_id'] + cfg.PRIMARY_TARGETS],\n",
    "        on='image_id',\n",
    "        how='inner',\n",
    "        suffixes=('', '_dino')\n",
    "    )\n",
    "    \n",
    "    merged = merged.merge(\n",
    "        siglip_preds[['image_id'] + cfg.PRIMARY_TARGETS],\n",
    "        on='image_id',\n",
    "        how='inner',\n",
    "        suffixes=('_dino', '_sig')\n",
    "    )\n",
    "    \n",
    "    # Sanity check\n",
    "    if len(merged) != len(siglip_preds) or len(merged) != len(dino_preds):\n",
    "        print(f\"WARNING: Row count mismatch! SigLIP={len(siglip_preds)}, DINO={len(dino_preds)}, Merged={len(merged)}\")\n",
    "    \n",
    "    print(f\"Merged {len(merged)} images\")\n",
    "    \n",
    "    # Ensemble primary targets\n",
    "    result = merged[['image_id']].copy()\n",
    "    \n",
    "    for col in cfg.PRIMARY_TARGETS:\n",
    "        dino_col = f\"{col}_dino\"\n",
    "        sig_col = f\"{col}_sig\"\n",
    "        \n",
    "        if cfg.DINO_ONLY_CLOVER and col == \"Dry_Clover_g\":\n",
    "            result[col] = merged[dino_col]\n",
    "            print(f\"  {col}: DINO only\")\n",
    "        else:\n",
    "            result[col] = cfg.W_DINO * merged[dino_col] + cfg.W_SIGLIP * merged[sig_col]\n",
    "            print(f\"  {col}: {cfg.W_DINO:.0%} DINO + {cfg.W_SIGLIP:.0%} SigLIP\")\n",
    "    \n",
    "    # Derive GDM and Total\n",
    "    result['GDM_g'] = result['Dry_Green_g'] + result['Dry_Clover_g']\n",
    "    result['Dry_Total_g'] = result['GDM_g'] + result['Dry_Dead_g']\n",
    "    \n",
    "    # Clip negatives\n",
    "    for col in cfg.TARGET_NAMES:\n",
    "        result[col] = result[col].clip(lower=0.0)\n",
    "    \n",
    "    print(\"\\nBuilding submission from test.csv template...\")\n",
    "    \n",
    "    test_template = test_df_raw.copy()\n",
    "    test_template['image_id'] = test_template['sample_id'].str.rsplit('__', n=1).str[0]\n",
    "    test_template['target_name'] = test_template['sample_id'].str.rsplit('__', n=1).str[1]\n",
    "    \n",
    "    # Merge predictions onto template\n",
    "    final = test_template.merge(result, on='image_id', how='left')\n",
    "    \n",
    "    # Pick the correct target value for each row\n",
    "    def get_target_value(row):\n",
    "        target_name = row['target_name']\n",
    "        return row.get(target_name, np.nan)\n",
    "    \n",
    "    final['target'] = final.apply(get_target_value, axis=1)\n",
    "    \n",
    "    # Final submission\n",
    "    submission = final[['sample_id', 'target']].copy()\n",
    "    \n",
    "    #SANITY CHECKS\n",
    "    print(\"\\n--- Sanity Checks ---\")\n",
    "    print(f\"Test rows (expected): {len(test_df_raw)}\")\n",
    "    print(f\"Submission rows: {len(submission)}\")\n",
    "    print(f\"Missing values: {submission['target'].isna().sum()}\")\n",
    "    print(f\"Columns: {submission.columns.tolist()}\")\n",
    "    \n",
    "    assert len(submission) == len(test_df_raw), \"Row count mismatch!\"\n",
    "    assert submission['target'].isna().sum() == 0, \"Missing predictions!\"\n",
    "    assert submission.columns.tolist() == ['sample_id', 'target'], \"Wrong columns!\"\n",
    "    \n",
    "    # Save\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(f\"\\n✓ Saved submission.csv with {len(submission)} rows\")\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(submission.head(10))\n",
    "    \n",
    "    print(\"\\nStats:\")\n",
    "    print(submission['target'].describe())\n",
    "    \n",
    "    return submission\n",
    "\n",
    "class SupervisedEmbeddingEngine:\n",
    "    \"\"\"\n",
    "    MATCHES TRAINING EXACTLY.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_pca=0.80, n_pls=8, n_gmm=6, random_state=42):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.pca = PCA(n_components=n_pca, random_state=random_state)\n",
    "        self.pls = PLSRegression(n_components=n_pls, scale=False)\n",
    "        self.gmm = GaussianMixture(n_components=n_gmm, covariance_type='diag', random_state=random_state)\n",
    "        self.pls_fitted_ = False\n",
    "\n",
    "    def fit(self, X, y=None, X_semantic=None):\n",
    "        # Scale\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Unsupervised\n",
    "        self.pca.fit(X_scaled)\n",
    "        self.gmm.fit(X_scaled)\n",
    "        \n",
    "        # Supervised\n",
    "        if y is not None:\n",
    "            self.pls.fit(X_scaled, y)\n",
    "            self.pls_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, X_semantic=None):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        features = [self.pca.transform(X_scaled)]\n",
    "        \n",
    "        if self.pls_fitted_:\n",
    "            features.append(self.pls.transform(X_scaled))\n",
    "            \n",
    "        features.append(self.gmm.predict_proba(X_scaled))\n",
    "        \n",
    "        if X_semantic is not None:\n",
    "            sem_norm = (X_semantic - np.mean(X_semantic, axis=0)) / (np.std(X_semantic, axis=0) + 1e-6)\n",
    "            features.append(sem_norm)\n",
    "            \n",
    "        return np.hstack(features)\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOADING TEST DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    test_df_raw = pd.read_csv(cfg.DATA_PATH / \"test.csv\")\n",
    "    print(f\"Test rows (raw): {len(test_df_raw)}\")\n",
    "    \n",
    "    # Convert to wide format for inference\n",
    "    test_df_wide = pivot_table_test(test_df_raw)\n",
    "    \n",
    "    test_df_wide['image_path'] = test_df_wide['image_path'].apply(\n",
    "        lambda x: str(cfg.DATA_PATH / \"test\" / os.path.basename(x))\n",
    "    )\n",
    "    print(f\"Test images: {len(test_df_wide)}\")\n",
    "    \n",
    "    for idx, row in test_df_wide.iterrows():\n",
    "        if not os.path.exists(row['image_path']):\n",
    "            print(f\"WARNING: Image not found: {row['image_path']}\")\n",
    "    \n",
    "    # Run SigLIP\n",
    "    siglip_preds = run_siglip_inference(test_df_wide)\n",
    "    \n",
    "    # Run DINO\n",
    "    dino_preds = run_dino_inference(test_df_wide)\n",
    "    \n",
    "    # Ensemble and submit\n",
    "    submission = ensemble_and_submit(siglip_preds, dino_preds, test_df_raw)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DONE!\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 9342294,
     "sourceId": 14625585,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9344124,
     "sourceId": 14628140,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9344173,
     "sourceId": 14628200,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 251887,
     "modelInstanceId": 230141,
     "sourceId": 268942,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 174.409545,
   "end_time": "2026-01-26T16:34:21.013863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-26T16:31:26.604318",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
